import os
import json
import re
import time
import logging
import hashlib
import html
from dotenv import load_dotenv
from datetime import datetime, timezone, timedelta, time as dt_time
from dateutil import parser
from zoneinfo import ZoneInfo
from typing import Dict, List, Optional, Tuple, Union
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from azure.data.tables import TableServiceClient
from openai import AzureOpenAI

load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


class EmailProcessor:
    """ì´ë©”ì¼ ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™” ë° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""

        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        self.azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        self.azure_openai_key = os.getenv("AZURE_OPENAI_KEY")
        self.azure_openai_deployment_chat = os.getenv(
            "AZURE_OPENAI_DEPLOYMENT_CHAT", "gpt-4"
        )
        self.azure_openai_deployment_emb = os.getenv(
            "AZURE_OPENAI_DEPLOYMENT_EMBEDDING", "text-embedding-3-small"
        )
        self.ai_search_endpoint = os.getenv("AI_SEARCH_ENDPOINT")
        self.ai_search_index = os.getenv("AI_SEARCH_INDEX", "emails-index")
        self.ai_search_admin_key = os.getenv("AI_SEARCH_ADMIN_KEY")
        self.azure_storage_connection_string = os.getenv(
            "AZURE_STORAGE_CONNECTION_STRING"
        )
        self.default_confidence = float(os.getenv("DEFAULT_CONFIDENCE", "0.65"))

        # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        self._validate_environment()

        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._initialize_clients()

        # ì„ë² ë”© ë°°í¬ëª… ìë™ ê°ì§€
        self._detect_embedding_deployment()

    def _validate_environment(self):
        """í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ê²€ì¦"""

        required_vars = {
            "AZURE_OPENAI_ENDPOINT": self.azure_openai_endpoint,
            "AZURE_OPENAI_KEY": self.azure_openai_key,
            "AI_SEARCH_ENDPOINT": self.ai_search_endpoint,
            "AI_SEARCH_ADMIN_KEY": self.ai_search_admin_key,
            "AZURE_STORAGE_CONNECTION_STRING": self.azure_storage_connection_string,
        }

        missing_vars = [key for key, value in required_vars.items() if not value]

        if missing_vars:
            raise ValueError(f"í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_vars}")

        logging.info("âœ… ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ ì™„ë£Œ")

    def _initialize_clients(self):
        """Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""

        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸
            self.openai_client = AzureOpenAI(
                azure_endpoint=self.azure_openai_endpoint,
                api_key=self.azure_openai_key,
                api_version="2024-02-01",
            )

            # AI Search í´ë¼ì´ì–¸íŠ¸
            self.search_client = SearchClient(
                endpoint=self.ai_search_endpoint,
                index_name=self.ai_search_index,
                credential=AzureKeyCredential(self.ai_search_admin_key),
            )

            # Table Storage í´ë¼ì´ì–¸íŠ¸
            self.table_service = TableServiceClient.from_connection_string(
                self.azure_storage_connection_string
            )

            logging.info("âœ… ëª¨ë“  Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logging.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _detect_embedding_deployment(self):
        """ì„ë² ë”© ë°°í¬ëª… ìë™ ê°ì§€"""

        # ì¼ë°˜ì ì¸ ì„ë² ë”© ë°°í¬ëª…ë“¤
        possible_names = [
            "text-embedding-3-small",
            "text-embedding-ada-002",
            "embedding-3-small",
            "embedding",
            self.azure_openai_deployment_emb,
        ]

        for deployment_name in possible_names:
            try:
                logging.info(f"ì„ë² ë”© ë°°í¬ëª… í…ŒìŠ¤íŠ¸: {deployment_name}")
                response = self.openai_client.embeddings.create(
                    model=deployment_name, input=["í…ŒìŠ¤íŠ¸"]
                )

                if response.data:
                    self.azure_openai_deployment_emb = deployment_name
                    logging.info(f"âœ… ì„ë² ë”© ë°°í¬ëª… í™•ì¸: {deployment_name}")
                    return

            except Exception as e:
                logging.warning(f"ë°°í¬ëª… '{deployment_name}' í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                continue

        # ëª¨ë“  ë°°í¬ëª… ì‹¤íŒ¨ì‹œ ì˜¤ë¥˜
        raise ValueError(
            "ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ë°°í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. AZURE_OPENAI_DEPLOYMENT_EMB í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )

    # ======================
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ / íŒíŠ¸
    # ======================
    def _pre_extract_deadlines(self, text: str, max_items: int = 5) -> List[str]:
        """
        ë³¸ë¬¸ì—ì„œ í•œêµ­ì–´ ê¸°í•œ í‘œí˜„ í›„ë³´ë¥¼ ë½‘ì•„ LLMì— íŒíŠ¸ë¡œ ì œê³µ.
        """
        patterns = [
            # 'ê¹Œì§€' ìˆëŠ” ìœ í˜•
            r"\(\s*\d{1,2}/\d{1,2}(?:\([^)]*\))?\s*ê¹Œì§€\s*\)",
            r"\d{1,2}/\d{1,2}(?:\([^)]*\))?\s*ê¹Œì§€",
            r"\d{4}-\d{1,2}-\d{1,2}(?:\s*\d{1,2}:\d{2})?\s*ê¹Œì§€",
            r"(?:ì´ë²ˆ\s*ì£¼|ê¸ˆì£¼)\s*(ì›”|í™”|ìˆ˜|ëª©|ê¸ˆ|í† |ì¼)ìš”ì¼?\s*ê¹Œì§€",
            r"(?:ê¸ˆì¼|ì˜¤ëŠ˜|ë‚´ì¼|ëª…ì¼)\s*(?:ì˜¤ì „|ì˜¤í›„)?\s*\d{1,2}ì‹œ(?:\s*\d{1,2}ë¶„)?\s*ê¹Œì§€",
            r"(?:ì˜¤ì „|ì˜¤í›„)?\s*\d{1,2}ì‹œ(?:\s*\d{1,2}ë¶„)?\s*ê¹Œì§€",
            r"(?:ê¸ˆì¼|ì˜¤ëŠ˜|ë‚´ì¼|ëª…ì¼)\s*ê¹Œì§€",
            # 'ê¹Œì§€' ì—†ëŠ” í”í•œ ë§ˆê°/ë²”ìœ„
            r"ë§ˆê°[:\s]*\d{1,2}/\d{1,2}(?:\([^)]*\))?",
            r"\b\d{1,2}/\d{1,2}\b(?:\s*\d{1,2}:\d{2})?",
            r"\d{4}-\d{1,2}-\d{1,2}",
            r"\d+\s*ì¼\s*(?:í›„|ë’¤)",
            r"\b(?:EOD|EOW)\b",
            r"(ì—…ë¬´\s*(?:ì¢…ë£Œ|ì‹œê°„)\s*ì „)",
            r"\d{1,2}/\d{1,2}\s*~\s*\d{1,2}/\d{1,2}",
            r"\d{4}-\d{1,2}-\d{1,2}\s*~\s*\d{4}-\d{1,2}-\d{1,2}",
            # ì£¼/ì›” ë‚´
            r"(ì´ë²ˆ\s*ì£¼\s*ë‚´|ì£¼ì¤‘|ì´ë²ˆ\s*ë‹¬\s*ë‚´|ì›”ë§\s*ê¹Œì§€|ë¶„ê¸°\s*ë§\s*ê¹Œì§€)",
        ]
        found = []
        for p in patterns:
            for m in re.finditer(p, text, flags=re.IGNORECASE):
                s = m.group(0).strip()
                if s not in found:
                    found.append(s)
                    if len(found) >= max_items:
                        return found
        return found

    def _collect_deadline_hints(self, email: Dict) -> List[str]:
        text_blob = f"{email.get('subject','')}\n\n{email.get('body','')}".strip()
        return self._pre_extract_deadlines(text_blob, max_items=10)

    def _collect_deadline_hints_from_text(self, text: str) -> List[str]:
        return self._pre_extract_deadlines(text, max_items=10)

    def _find_context(self, text: str, snippet: str, width: int = 80) -> str:
        i = text.find(snippet)
        if i == -1:
            return ""
        start = max(0, i - width)
        end = min(len(text), i + len(snippet) + width)
        return text[start:end]


    # ======================
    # ë©˜ì…˜/ì„¸ê·¸ë¨¼íŠ¸ ë¡œì§
    # ======================
    def _is_self_mention_text(self, mention_text: str, user_context: dict) -> bool:
        """ë©˜ì…˜ ë¬¸ìì—´ì´ ë‚˜ì¸ì§€ íŒë³„"""
        name = (user_context.get("name") or "").strip()
        email = (user_context.get("email") or "").strip().lower()
        team = (user_context.get("team") or "").strip()

        # ë©˜ì…˜ ì›ë¬¸ ì •ë¦¬
        raw = mention_text.strip()
        if not raw.startswith("@"):
            return False

        # '@' ì œê±°, ê´„í˜¸ ë‚´ìš© ì œê±° â†’ "@ë°•ì§€í›ˆ(ë°±ì—”ë“œê°œë°œíŒ€)" -> "ë°•ì§€í›ˆ"
        base = raw.lstrip("@").split("(", 1)[0]
        base = base.replace(" ", "").lower()
        # ì¡´ì¹­/ë¶ˆìš©ì–´ ì œê±°
        base = re.sub(r"(ë‹˜|ì”¨|ë‹˜ë“¤)$", "", base)

        packed = raw.replace(" ", "").lower()

        # ì´ë©”ì¼ ë¡œì»¬ íŒŒíŠ¸ë„ ë¹„êµ (ex. jihoon.park)
        email_local = email.split("@")[0] if email else ""

        return any(
            [
                # ì •í™• ì´ë¦„ ë§¤ì¹­ (ê³µë°± ì œê±°, ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
                (name and base == name.replace(" ", "").lower()),
                # '@ë°•ì§€í›ˆ...' í˜•íƒœ ì‹œì‘ ë§¤ì¹­
                (name and packed.startswith("@" + name.replace(" ", "").lower())),
                # ì´ë©”ì¼ í¬í•¨
                (email and email in packed),
                # ì´ë©”ì¼ ë¡œì»¬ íŒŒíŠ¸ ë§¤ì¹­
                (email_local and base == email_local),
                # íŒ€ëª… í¬í•¨ (@ë°±ì—”ë“œê°œë°œíŒ€)
                (team and team.replace(" ", "").lower() in packed),
            ]
        )

    def _get_self_mention_segments(
        self,
        text: str,
        user_context: dict,
        max_chars: int = 1500,
        max_lines: int = 25,
    ) -> List[Tuple[int, int, str]]:
        """
        ë‚´ ë©˜ì…˜(ë˜ëŠ” ë‚´ê°€ í¬í•¨ëœ ë©˜ì…˜ í´ëŸ¬ìŠ¤í„°)ë¶€í„° ë‹¤ìŒ ë©˜ì…˜ ì§ì „ê¹Œì§€ë¥¼ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë°˜í™˜.
        - ê°™ì€ ì¤„ì—ì„œ ë©˜ì…˜ì´ ì—°ì† ë“±ì¥í•˜ê³  ê°„ê²© â‰¤ 80ìë©´ ê°™ì€ í´ëŸ¬ìŠ¤í„°ë¡œ ì·¨ê¸‰(ê³µë™ì§€ì‹œ).
        - ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘ì„ í´ëŸ¬ìŠ¤í„° ì‹œì‘ì—ì„œ 50ì ì•(backoff)ìœ¼ë¡œ ë‹¹ê²¨, ë©˜ì…˜ ë¬¸ë§¥ì´ LLM/ê²€ì¦ ë‹¨ê³„ì— í•­ìƒ ì¶”ê°€ë˜ë„ë¡ ë³´ì¥.
        - ë¹ˆ ì¤„ì—ì„œ ì¶”ê°€ ì»·, ê¸¸ì´ ì œí•œ ìœ ì§€.
        """
        mention_re = r"@[A-Za-zê°€-í£0-9_.\-]+(?:\([^)]+\))?"
        mentions = list(re.finditer(mention_re, text))
        if not mentions:
            return []

        CLUSTER_GAP = 80
        BACKOFF = 50  # ë©˜ì…˜ ì•ìª½ ë¬¸ë§¥ ì¡°ê¸ˆ í¬í•¨

        segs: List[Tuple[int, int, str]] = []
        i = 0
        while i < len(mentions):
            # ië¶€í„° í´ëŸ¬ìŠ¤í„° êµ¬ì„±(ê°™ì€ ì¤„ & GAP ì´í•˜)
            cluster = [mentions[i]]
            j = i + 1
            while j < len(mentions):
                gap = text[mentions[j - 1].end() : mentions[j].start()]
                if ("\n" not in gap) and (len(gap) <= CLUSTER_GAP):
                    cluster.append(mentions[j])
                    j += 1
                else:
                    break

            # ë‚´ê°€ í¬í•¨ëœ í´ëŸ¬ìŠ¤í„°ë§Œ ì„¸ê·¸ë¨¼íŠ¸ ëŒ€ìƒ
            if any(
                self._is_self_mention_text(m.group(0), user_context) for m in cluster
            ):
                cluster_start = cluster[0].start()
                cluster_end = cluster[-1].end()
                next_start = mentions[j].start() if j < len(mentions) else len(text)

                # ğŸ”¹ ë©˜ì…˜ì„ í¬í•¨ì‹œí‚¤ê³ , ì‚´ì§ ì•(backoff)ê¹Œì§€ ë„£ì–´ì¤€ë‹¤
                seg_start = max(0, cluster_start - BACKOFF)
                seg_end = next_start

                seg = text[seg_start:seg_end]

                # ë‹¨ë½ ê²½ê³„(ë¹ˆ ì¤„)ì—ì„œ ì»·
                m_blank = re.search(r"\n\s*\n", seg)
                if m_blank:
                    seg = seg[: m_blank.start()]

                # ê¸¸ì´ ì œí•œ
                lines = seg.splitlines()
                if len(lines) > max_lines:
                    seg = "\n".join(lines[:max_lines])
                if len(seg) > max_chars:
                    seg = seg[:max_chars]

                segs.append((seg_start, seg_start + len(seg), seg))

            i = j

        return segs

    def _is_due_for_user(self, text: str, cand: str, user_context: dict) -> bool:
        """
        'ë‚˜'ì—ê²Œ ìœ íš¨í•œ ë§ˆê°(due_raw)ì¸ì§€ íŒë³„.
        ê·œì¹™:
        1) ë‚´ ë©˜ì…˜ ~ ë‹¤ìŒ ë©˜ì…˜ ì‚¬ì´ êµ¬ê°„ì— candê°€ ìˆìœ¼ë©´ ë‚´ ê²ƒ.
        2) ì—¬ëŸ¬ ë©˜ì…˜ì´ í•œ ì¤„/ì§§ì€ ê°„ê²©(ê°™ì€ ë¬¸ì¥)ìœ¼ë¡œ ë¬¶ì¸ 'í´ëŸ¬ìŠ¤í„°' ì§í›„ candê°€ ë‚˜ì˜¤ë©´,
           ê·¸ í´ëŸ¬ìŠ¤í„°ì— ë‚´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë‚´ ê²ƒìœ¼ë¡œ ê°„ì£¼(ê³µë™ ì§€ì‹œ).
        3) cand ì§ì „ ìœˆë„ìš°ì—ì„œ ë§ˆì§€ë§‰ ë©˜ì…˜ì´ 'ë‚˜'ë¼ë©´ ë‚´ ê²ƒ.
        4) ë©˜ì…˜ì´ ì „í˜€ ì—†ìœ¼ë©´ ê¸°ì¡´ ì™„í™” ê·œì¹™.
        """
        name = (user_context.get("name") or "").strip()
        email = (user_context.get("email") or "").strip()
        team = (user_context.get("team") or "").strip()

        cand_idx = text.find(cand)
        if cand_idx == -1:
            return False

        # ëª¨ë“  ë©˜ì…˜ ìˆ˜ì§‘
        mention_re = r"@[A-Za-zê°€-í£0-9_.]+(?:\([^)]+\))?"
        mentions = list(re.finditer(mention_re, text))

        # ë©˜ì…˜ì´ ì—†ìœ¼ë©´: ì™„í™” ê·œì¹™
        if not mentions:
            ctx = self._find_context(text, cand, width=80)
            return any(
                [
                    name and (name in ctx),
                    email and (email in ctx),
                    team and (team in ctx),
                    re.search(
                        r"(ì•„ë˜\s*ì‘ì—…|ë‹¤ìŒ\s*ì‘ì—…).*(ê¹Œì§€|ë§ˆê°|ë¶€íƒ|ìš”ì²­|í™•ì¸)", ctx
                    ),
                ]
            )

        # 1) ê¸°ë³¸: ë‚´ ë©˜ì…˜ ~ ë‹¤ìŒ ë©˜ì…˜ ì‚¬ì´ êµ¬ê°„
        for i, m in enumerate(mentions):
            if self._is_self_mention_text(m.group(0), user_context):
                seg_start = m.end()
                seg_end = (
                    mentions[i + 1].start() if i + 1 < len(mentions) else len(text)
                )
                if seg_start <= cand_idx < seg_end:
                    return True

        # 2) ë©˜ì…˜ í´ëŸ¬ìŠ¤í„°(ê°™ì€ ë¬¸ì¥/ì§§ì€ ê°„ê²©) ì§í›„ cand â†’ í´ëŸ¬ìŠ¤í„°ì— ë‚´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ True
        CLUSTER_GAP = 80
        last_before_idx = -1
        for i, m in enumerate(mentions):
            if m.start() < cand_idx:
                last_before_idx = i
            else:
                break

        if last_before_idx >= 0:
            cluster = [mentions[last_before_idx]]
            j = last_before_idx - 1
            while j >= 0:
                prev = mentions[j]
                gap_text = text[prev.end() : cluster[0].start()]
                if ("\n" not in gap_text) and (len(gap_text) <= CLUSTER_GAP):
                    cluster.insert(0, prev)
                    j -= 1
                else:
                    break

            cluster_end = cluster[-1].end()
            has_mention_between = any(
                m.start() >= cluster_end and m.start() < cand_idx for m in mentions
            )
            if not has_mention_between:
                if any(
                    self._is_self_mention_text(m.group(0), user_context)
                    for m in cluster
                ):
                    return True

        # 3) cand ì§ì „ ìœˆë„ìš°(200ì)ì—ì„œ ë§ˆì§€ë§‰ ë©˜ì…˜ì´ ë‚˜
        window_start = max(0, cand_idx - 200)
        ctx = text[window_start:cand_idx]
        last_any = None
        for m in re.finditer(mention_re, ctx):
            last_any = m
        if last_any:
            if self._is_self_mention_text(last_any.group(0), user_context):
                tail = ctx[last_any.end() :]
                if ("\n" not in tail) or re.search(
                    r"(ê¹Œì§€|ë§ˆê°|ë¶€íƒ|ìš”ì²­|í™•ì¸|ì™„ë£Œ)", tail
                ):
                    return True

        return False

    # ======================
    # HTML â†’ TEXT ì „í™˜
    # ======================
    def _html_to_text(self, html_str: str) -> str:
        if not html_str:
            return ""
        text = re.sub(r"(?is)<(script|style).*?>.*?</\1>", " ", html_str)
        text = re.sub(r"(?is)<br\s*/?>", "\n", text)
        text = re.sub(r"(?is)</p>", "\n", text)
        text = re.sub(r"(?is)</li>", "\n- ", text)
        text = re.sub(r"(?is)<[^>]+>", " ", text)
        text = html.unescape(text)
        text = re.sub(r"[ \t\u00A0]+", " ", text)
        text = re.sub(r"\n{3,}", "\n\n", text)
        return text.strip()

    # ======================
    # ì´ë©”ì¼ í‘œì¤€í™”
    # ======================
    def preprocess_email(self, email_data: Dict) -> Dict:
        """ì´ë©”ì¼ ë°ì´í„° ì „ì²˜ë¦¬ (ì•ˆì „í•œ ì²˜ë¦¬)"""

        # ì•ˆì „í•œ í•„ë“œ ì¶”ì¶œ
        def safe_get(key: str, default: str = "") -> str:
            value = email_data.get(key)
            return str(value) if value is not None else default

        def safe_get_list(key: str, default_list: List = None) -> List:
            value = email_data.get(key)
            if isinstance(value, list):
                return value
            return default_list or []

        # ê¸°ë³¸ ì •ì œ
        body = safe_get("email_body")
        html_body = safe_get("html_body")

        # âœ… í•­ìƒ ë³‘í•© (ì¤‘ë³µ ì¤„ ì œê±°)
        if html_body:
            html_text = self._html_to_text(html_body)
            if html_text:
                merged = (body + "\n\n" + html_text).strip() if body else html_text
                # ì¤‘ë³µ ë¼ì¸ ê°„ë‹¨ ì œê±°
                lines = []
                seen = set()
                for ln in merged.splitlines():
                    key = ln.strip()
                    if key and key not in seen:
                        lines.append(ln)
                        seen.add(key)
                body = "\n".join(lines)

        # ì„œëª…/ê´‘ê³  ë¸”ë¡ ì œê±° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        signature_patterns = [r"\n\n--\n.*", r"\n\n.*ë“œë¦¼$", r"\n\n.*ê°ì‚¬í•©ë‹ˆë‹¤\..*"]
        for pattern in signature_patterns:
            body = re.sub(pattern, "", body, flags=re.DOTALL | re.MULTILINE)

        # ì£¼ì†Œë¡ ë°°ì—´ ì •ê·œí™”
        to_names = safe_get_list("to_names")
        to_addresses = safe_get_list("to_addresses")
        cc_names = safe_get_list("cc_names")
        cc_addresses = safe_get_list("cc_addresses")

        max_to_len = max(len(to_names), len(to_addresses))
        max_cc_len = max(len(cc_names), len(cc_addresses))

        to_list = []
        for i in range(max_to_len):
            name = to_names[i] if i < len(to_names) else ""
            email = to_addresses[i] if i < len(to_addresses) else ""
            if name or email:
                to_list.append({"name": name, "email": email})

        cc_list = []
        for i in range(max_cc_len):
            name = cc_names[i] if i < len(cc_names) else ""
            email = cc_addresses[i] if i < len(cc_addresses) else ""
            if name or email:
                cc_list.append({"name": name, "email": email})

        threads = email_data.get("threads", {})
        keywords = []
        if isinstance(threads, dict):
            keywords = threads.get("keywords", [])
            if not isinstance(keywords, list):
                keywords = []

        standardized = {
            "recordId": safe_get("recordId"),
            "emailId": safe_get("email_id"),
            "subject": safe_get("subject"),
            "from": {"name": safe_get("from_name"), "email": safe_get("from_address")},
            "to": to_list,
            "cc": cc_list,
            "receivedAt": safe_get("date"),
            "body": body.strip(),
            "html_body": html_body,
            "conversationId": safe_get("thread_id"),
            "priority_hint": safe_get("priority"),
            "keywords": keywords,
        }

        return standardized

    # ======================
    # ì •ì±… ì—”ì§„
    # ======================
    def analyze_with_policy_engine(self, email_data: Dict, user_context: Dict) -> Dict:
        """ì •ì±… ì—”ì§„ ë¶„ì„ (ì•ˆì „í•œ ì²˜ë¦¬)"""

        # ì•ˆì „í•œ í•„ë“œ ì¶”ì¶œ
        from_email = email_data.get("from_address", "")
        to_emails = email_data.get("to_addresses", [])
        cc_emails = email_data.get("cc_addresses", [])
        body = email_data.get("email_body", "")

        if not isinstance(to_emails, list):
            to_emails = []
        if not isinstance(cc_emails, list):
            cc_emails = []
        if not isinstance(body, str):
            body = ""
        if not isinstance(from_email, str):
            from_email = ""

        user_name = user_context.get("name", "")
        user_email = user_context.get("email", "")
        user_team = user_context.get("team", "")

        mentions = []
        if body:
            try:
                mentions = re.findall(r"@(\S+(?:\([^)]+\))?)", body)
                mentions = [f"@{mention}" for mention in mentions]
            except Exception as e:
                logging.warning(f"ë©˜ì…˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                mentions = []

        request_keywords = [
            "ë¶€íƒ",
            "ìš”ì²­",
            "í™•ì¸",
            "ê²€í† ",
            "ìŠ¹ì¸",
            "íšŒì‹ ",
            "ì¦‰ì‹œ",
            "ê¸´ê¸‰",
            "ë§ˆê°",
            "ì™„ë£Œ",
            "í•´ì£¼ì„¸ìš”",
            "ë°”ëë‹ˆë‹¤",
            "ì²˜ë¦¬",
            "ëŒ€ì‘",
            "ë¶„ì„",
            "ì ê²€",
            "ì‹¤í–‰",
        ]
        request_detected = False
        if body:
            try:
                request_detected = any(keyword in body for keyword in request_keywords)
            except Exception as e:
                logging.warning(f"ìš”ì²­ í‚¤ì›Œë“œ ê°ì§€ ì‹¤íŒ¨: {e}")
                request_detected = False

        self_sent = bool(from_email and user_email and from_email == user_email)
        to_contains_self = bool(user_email and user_email in to_emails)
        cc_contains_self = bool(user_email and user_email in cc_emails)

        policy_decision = "none"
        try:
            if to_contains_self and request_detected:
                user_mentions = [
                    mention
                    for mention in mentions
                    if user_name and f"@{user_name}" in mention
                ]
                if (
                    not any(
                        mention for mention in mentions if mention != f"@{user_name}"
                    )
                ) or user_mentions:
                    policy_decision = "A"
            elif cc_contains_self and not to_contains_self:
                if any(
                    user_name and f"@{user_name}" in mention for mention in mentions
                ):
                    policy_decision = "A"  # ëª…ì‹œì  ì§€ëª©ì´ë©´ ì•¡ì…˜
                else:
                    policy_decision = "B"
            elif self_sent and request_detected:
                policy_decision = "C"
            elif (
                to_contains_self
                and user_team
                and user_team in body
                and request_detected
            ):
                policy_decision = "D"
        except Exception as e:
            logging.warning(f"ì •ì±… ê²°ì • ì¤‘ ì˜¤ë¥˜: {e}")
            policy_decision = "none"

        return {
            "policy_decision": policy_decision,
            "self_sent": self_sent,
            "to_contains_self": to_contains_self,
            "cc_contains_self": cc_contains_self,
            "mentions": mentions,
            "request_detected": request_detected,
        }

    # ======================
    # ì„¸ê·¸ë¨¼íŠ¸ ì „ìš© LLM í”„ë¡¬í”„íŠ¸/ê²€ì¦
    # ======================
    def _build_action_prompt_for_segment(
        self,
        email_data: Dict,
        policy_signals: Dict,
        user_context: Dict,
        segment_text: str,
        deadline_hints: List[str],
    ) -> Tuple[str, str]:
        name = user_context["name"]
        email = user_context["email"]
        team = user_context["team"]

        followup_hint = ""
        if policy_signals.get("self_sent"):
            # ğŸ”¸ ë‚´ê°€ ë³´ë‚¸ ë©”ì¼ì´ë¼ë©´ FOLLOW_UP ëª¨ë“œ ê°•ì œ
            followup_hint = (
                "\n- ì´ ë©”ì¼ì€ ë‚´ê°€ ë³´ë‚¸ ìš”ì²­ì´ë¯€ë¡œ action.typeì€ ë°˜ë“œì‹œ FOLLOW_UP ì…ë‹ˆë‹¤."
                "\n- FOLLOW_UPì—ì„œëŠ” 'ìƒëŒ€ì—ê²Œ ìš”ì²­í•œ í•µì‹¬ ì‘ì—…'ì„ titleë¡œ 12~20ìë¡œ ìš”ì•½í•˜ì„¸ìš”(ì˜ˆ: \"ë¡œê·¸ ë¶„ì„ ê²°ê³¼ íšŒì‹  ìš”ì²­\")."
                "\n- assignee_candidatesì—ëŠ” ë‚´ ì£¼ì†Œê°€ ì•„ë‹ˆë¼ 'ìƒëŒ€ ìˆ˜ì‹ ì/íŒ€'ì„ ë„£ìœ¼ì„¸ìš”."
                "\n- due_rawëŠ” ì„¸ê·¸ë¨¼íŠ¸(ë˜ëŠ” ì´ ì„¸ê·¸ë¨¼íŠ¸ ì•ˆì—ì„œ ë³´ì´ëŠ” ë¬¸ì¥)ì—ì„œ ë°œê²¬ë˜ëŠ” ê¸°í•œ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì„¸ìš”(ì—†ìœ¼ë©´ null)."
            )

        system_prompt = f"""
    ë‹¹ì‹ ì€ ì´ë©”ì¼ì—ì„œ 'ìˆ˜ì‹ ì {name}<{email}>' ë˜ëŠ” '{team}' íŒ€(ê·¸ë¦¬ê³  {name}ì´ Toì— í¬í•¨)ì—
    ì‹¤ì œë¡œ ë°°ì •ëœ ì•¡ì…˜ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. JSON í•œ ì¤„ë§Œ ì¶œë ¥í•˜ì„¸ìš”(ìš”ì•½/ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€).

    ê·œì¹™:
    - ì´ í”„ë¡¬í”„íŠ¸ëŠ” 'ì„¸ê·¸ë¨¼íŠ¸' í…ìŠ¤íŠ¸ë§Œ ì œê³µí•©ë‹ˆë‹¤. ë°˜ë“œì‹œ 'ì„¸ê·¸ë¨¼íŠ¸ ë²”ìœ„ ë‚´'ì—ì„œë§Œ ì•¡ì…˜ì„ ì¶”ì¶œí•˜ì„¸ìš”.
    - 'ë°°ì •ë¨' = (ë‚´ ì´ë©”ì¼ To) ë˜ëŠ” (@{name} ë©˜ì…˜/ë‚´ê°€ í¬í•¨ëœ ë©˜ì…˜ í´ëŸ¬ìŠ¤í„°) ë˜ëŠ” (íŒ€ë‹¨ìœ„ ì§€ì‹œ + Toì— ë‚´ê°€ í¬í•¨).
    - title: 12~20ì, ë™ì‚¬+ëª…ì‚¬(ì˜ˆ: "API ë¡œê·¸ ë¶„ì„").
    - due_raw: ì›ë¬¸ ê·¸ëŒ€ë¡œ ë³µì‚¬(ì˜ˆ: "ê¸ˆì¼ ì˜¤í›„ 2ì‹œê¹Œì§€"). ì„¸ê·¸ë¨¼íŠ¸ ë°–ì€ ì ˆëŒ€ ë³´ì§€ ë§ˆì„¸ìš”.
    - ê°’ì´ ì—†ìœ¼ë©´ null.{followup_hint}

    - JSON ìŠ¤í‚¤ë§ˆ:
    {{"is_action":true/false,"policy_decision":"A|B|C|D|none",
    "action":{{"type":"DO|FOLLOW_UP|NONE","title":"", "assignee_candidates":["ì´ë¦„ <ì´ë©”ì¼>","íŒ€ëª…"],"due_raw":null,"priority":"High|Medium|Low","tags":["íƒœê·¸1","íƒœê·¸2"],"rationale":""}}}}
    """.strip()

        user_prompt = f"""
    [ì„¸ê·¸ë¨¼íŠ¸ ì „ìš© ë³¸ë¬¸]
    {segment_text[:3000]}

    [ì„¸ê·¸ë¨¼íŠ¸ ë‚´ ê¸°í•œ í›„ë³´ íŒíŠ¸]: {deadline_hints}

    ì •ì±… ì‹ í˜¸:
    - ì •ì±… ê²°ì •: {policy_signals['policy_decision']}
    - ë³¸ì¸ ë°œì†¡: {policy_signals['self_sent']}
    - Toì— ë³¸ì¸ í¬í•¨: {policy_signals['to_contains_self']}
    - ë©˜ì…˜: {policy_signals['mentions']}
    - ìš”ì²­ ê°ì§€: {policy_signals['request_detected']}

    ì£¼ì˜: ì˜¤ì§ JSON í•œ ì¤„ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    """.strip()

        return system_prompt, user_prompt

    def _validate_and_fix_action(
        self,
        result: Dict,
        context_text: str,
        hints: List[str],
        policy_signals: Dict,
        user_context: Dict,
    ) -> Dict:
        if not isinstance(result, dict):
            return {"is_action": False, "policy_decision": "none", "action": None}

        is_action = bool(result.get("is_action"))
        policy = result.get("policy_decision") or policy_signals.get(
            "policy_decision", "none"
        )
        action = result.get("action") or {}

        a_type = (action.get("type") or "NONE").upper()
        if a_type not in {"DO", "FOLLOW_UP", "NONE"}:
            a_type = "NONE"

        # ğŸ”¸ ë‚´ê°€ ë³´ë‚¸ ë©”ì¼ì´ë©´ ë¬´ì¡°ê±´ FOLLOW_UPë¡œ êµì •
        if policy_signals.get("self_sent"):
            a_type = "FOLLOW_UP"
            is_action = True

        title = (action.get("title") or "").strip()
        if len(title) > 20:
            title = title[:20].rstrip()

        priority = action.get("priority") or "Medium"
        tags = action.get("tags") or []
        if not isinstance(tags, list):
            tags = [str(tags)]
        tags = list(dict.fromkeys([str(t) for t in tags]))

        assignees = action.get("assignee_candidates") or []

        due_raw = (action.get("due_raw") or "").strip() or None
        # ğŸ”¸ FOLLOW_UPì€ ë‚´ due ë§¥ë½ ê²€ì¦ì—ì„œ ì œì™¸(ìš”ì²­ ìƒëŒ€ì˜ ê¸°í•œì¼ ìˆ˜ ìˆìŒ)
        if due_raw and a_type != "FOLLOW_UP":
            if not self._is_due_for_user(context_text, due_raw, user_context):
                logging.info(
                    "ğŸš« íƒ€ì¸ ì§€ì‹œ ë§¥ë½ìœ¼ë¡œ due_raw ë¬´íš¨í™”(ì„¸ê·¸ë¨¼íŠ¸ ê²€ì¦): %s", due_raw
                )
                due_raw = None

        if a_type == "NONE":
            is_action = False
            action_out = None
        else:
            action_out = {
                "type": a_type,
                "title": title,
                "assignee_candidates": assignees,
                "due_raw": due_raw,
                "priority": priority,
                "tags": tags,
                "rationale": action.get("rationale", ""),
            }

        return {"is_action": is_action, "policy_decision": policy, "action": action_out}

    # ======================
    # LLM ì¶”ì¶œ (ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜)
    # ======================
    def extract_actions_with_llm(
        self, email_data: Dict, policy_signals: Dict, user_context: Dict
    ) -> Dict:
        """
        1) ë³¸ë¬¸ì—ì„œ ë‚´ ë©˜ì…˜/í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ 'ì„¸ê·¸ë¨¼íŠ¸'ë¥¼ ìë¦„
        2) ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ LLM JSON ì¶”ì¶œ
        3) ì²« ìœ íš¨ ì•¡ì…˜ ë°˜í™˜(ì—†ìœ¼ë©´ ì „ì²´ ë³¸ë¬¸ìœ¼ë¡œ 1íšŒ í´ë°±)
        """
        full_subject = email_data.get("subject", "")
        full_body = email_data.get("body", "")
        text_blob_full = f"{full_subject}\n\n{full_body}"

        segments = self._get_self_mention_segments(full_body, user_context)
        tried_any = False

        def _postfix(result: Dict, seg_text: str, hints: List[str]) -> Dict:
            return self._validate_and_fix_action(
                result,
                f"{full_subject}\n\n{seg_text}",
                hints,
                policy_signals,
                user_context,
            )

        # 1) ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹œë„
        for idx, (_, _, seg_text) in enumerate(segments):
            tried_any = True
            hints = self._collect_deadline_hints_from_text(seg_text)
            sys_p, usr_p = self._build_action_prompt_for_segment(
                email_data, policy_signals, user_context, seg_text, hints
            )

            try:
                logging.info(
                    "=== ğŸ“¤ LLM ìš”ì²­ (segment #%d system) ===\n%s", idx + 1, sys_p
                )
                logging.info(
                    "=== ğŸ“¤ LLM ìš”ì²­ (segment #%d user) ===\n%s", idx + 1, usr_p
                )

                resp = self.openai_client.chat.completions.create(
                    model=self.azure_openai_deployment_chat,
                    messages=[
                        {"role": "system", "content": sys_p},
                        {"role": "user", "content": usr_p},
                    ],
                    temperature=0.1,
                    max_tokens=600,
                )
                raw = (resp.choices[0].message.content or "").strip()
                logging.info("=== ğŸ“¥ LLM ì‘ë‹µ (segment #%d) ===\n%s", idx + 1, raw)

                # JSONë§Œ ì¶”ì¶œ
                m = re.search(r"\{.*\}\s*$", raw, flags=re.DOTALL)
                if m:
                    raw = m.group(0)
                result = json.loads(raw)

                result = _postfix(result, seg_text, hints)
                if result.get("is_action") and result.get("action"):
                    logging.info("âœ… ì„¸ê·¸ë¨¼íŠ¸ #%d ì—ì„œ ì•¡ì…˜ í™•ì •", idx + 1)
                    return result

            except Exception as e:
                logging.warning("ì„¸ê·¸ë¨¼íŠ¸ #%d ì²˜ë¦¬ ì‹¤íŒ¨: %s", idx + 1, e)

        # 2) ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ê±°ë‚˜ ë‹¤ ì‹¤íŒ¨ â†’ ì „ì²´ ë³¸ë¬¸ìœ¼ë¡œ ë§ˆì§€ë§‰ 1íšŒ ì‹œë„
        if not tried_any:
            deadline_hints = self._collect_deadline_hints(email_data)
            sys_p, usr_p = self._build_action_prompt_for_segment(
                email_data, policy_signals, user_context, full_body, deadline_hints
            )
            try:
                logging.info("=== ğŸ“¤ LLM ìš”ì²­ (fallback system) ===\n%s", sys_p)
                logging.info("=== ğŸ“¤ LLM ìš”ì²­ (fallback user) ===\n%s", usr_p)
                resp = self.openai_client.chat.completions.create(
                    model=self.azure_openai_deployment_chat,
                    messages=[
                        {"role": "system", "content": sys_p},
                        {"role": "user", "content": usr_p},
                    ],
                    temperature=0.1,
                    max_tokens=600,
                )
                raw = (resp.choices[0].message.content or "").strip()
                logging.info("=== ğŸ“¥ LLM ì‘ë‹µ (fallback) ===\n%s", raw)
                m = re.search(r"\{.*\}\s*$", raw, flags=re.DOTALL)
                if m:
                    raw = m.group(0)
                result = json.loads(raw)
                result = self._validate_and_fix_action(
                    result, text_blob_full, deadline_hints, policy_signals, user_context
                )
                logging.info(
                    "âœ… LLM ì•¡ì…˜ ì¶”ì¶œ ì™„ë£Œ: %s", result.get("is_action", False)
                )
                return result
            except Exception as e:
                logging.exception("âŒ LLM ì¶”ì¶œ ì‹¤íŒ¨(í´ë°±)")
                return {"is_action": False, "policy_decision": "none", "action": None}

        # ì„¸ê·¸ë¨¼íŠ¸ëŠ” ìˆì—ˆì§€ë§Œ ëª¨ë‘ ë¹„ì•¡ì…˜/ì‹¤íŒ¨
        return {
            "is_action": False,
            "policy_decision": policy_signals.get("policy_decision", "none"),
            "action": None,
        }

    # ======================
    # ë§ˆê° í•´ì„(KST/UTC) + LLM ë³´ì •
    # ======================
    def _llm_resolve_deadline(
        self, due_raw: str, received_at_iso: Optional[str]
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        ê·œì¹™ íŒŒì‹±ì´ ì•ˆ ë  ë•Œ LLMë¡œ ìƒëŒ€í‘œí˜„ì„ ì ˆëŒ€ì‹œê°„ìœ¼ë¡œ ë³´ì •.
        ë°˜í™˜: (resolved_kst_str "YYYY-MM-DD HH:MM KST", resolved_utc_iso) ë˜ëŠ” (None, None)
        """
        try:
            kst = ZoneInfo("Asia/Seoul")
            now_kst = None
            if received_at_iso:
                tmp = parser.parse(received_at_iso)
                now_kst = tmp.astimezone(kst) if tmp.tzinfo else tmp.replace(tzinfo=kst)
            if not now_kst:
                now_kst = datetime.now(kst)

            system_prompt = (
                "ë„ˆëŠ” í•œêµ­ì–´ ê¸°í•œ í‘œí˜„ì„ KST ê¸°ì¤€ì˜ ëª…í™•í•œ ë‚ ì§œ/ì‹œê°„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„ìš°ë¯¸ì•¼.\n"
                '- ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í•œ ì¤„: {"kst":"YYYY-MM-DD HH:MM","iso":"YYYY-MM-DDTHH:MM:SSZ"}\n'
                "- ì‹œê°„ì´ ì—†ìœ¼ë©´ 18:00ìœ¼ë¡œ ê°€ì •.\n"
                "- 'ê¸ˆì¼/ì˜¤ëŠ˜'=ìˆ˜ì‹ ì¼, 'ëª…ì¼/ë‚´ì¼'=+1, 'ëª¨ë ˆ'=+2.\n"
                "- 'ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼'=ìˆ˜ì‹ ì¼ì´ ì†í•œ ì£¼ì˜ ê¸ˆìš”ì¼.\n"
                "- 'ë‹¤ìŒ ì£¼/ì°¨ì£¼ í™”ìš”ì¼'=ë‹¤ìŒ ì£¼ì˜ í™”ìš”ì¼.\n"
                "- ë¶ˆê°€ëŠ¥í•˜ë©´ ë‘ ê°’ ëª¨ë‘ null."
            )
            user_prompt = (
                f"ì›ë¬¸: {due_raw}\n"
                f"ìˆ˜ì‹ ì‹œê°(KST): {now_kst.strftime('%Y-%m-%d %H:%M:%S')}\n"
                "í•œ ì¤„ JSONìœ¼ë¡œë§Œ ë‹µí•´."
            )

            resp = self.openai_client.chat.completions.create(
                model=self.azure_openai_deployment_chat,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.0,
                max_tokens=120,
            )
            raw = (resp.choices[0].message.content or "").strip()
            data = json.loads(raw)

            kst_str = data.get("kst")
            iso = data.get("iso")
            if (
                kst_str
                and re.match(r"^\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}$", kst_str)
                and iso
                and iso.endswith("Z")
            ):
                return f"{kst_str} KST", iso
        except Exception as e:
            logging.info(f"LLM ê¸°í•œ ë³´ì • ì‹¤íŒ¨: {e}")
        return None, None

    def _resolve_relative_deadline(
        self, due_raw: str, received_at_iso: Optional[str]
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        ìƒëŒ€/ëª¨í˜¸ í‘œí˜„(due_raw)ì„ KST/UTCë¡œ í•´ì„.
        ìš°ì„  ê·œì¹™ìœ¼ë¡œ ì‹œë„, ì‹¤íŒ¨ ì‹œ _llm_resolve_deadline()ìœ¼ë¡œ ë³´ì •.
        ë°˜í™˜: (resolved_kst_str 'YYYY-MM-DD HH:MM KST', resolved_utc_iso)
        """
        if not due_raw:
            return None, None

        kst = ZoneInfo("Asia/Seoul")
        # ê¸°ì¤€ì‹œê°: ìˆ˜ì‹ ì‹œê°ì´ ìˆìœ¼ë©´ ê·¸ê²ƒ, ì—†ìœ¼ë©´ now
        try:
            if received_at_iso:
                base = parser.parse(received_at_iso)
                now_kst = (
                    base.astimezone(kst) if base.tzinfo else base.replace(tzinfo=kst)
                )
            else:
                now_kst = datetime.now(kst)
        except Exception:
            now_kst = datetime.now(kst)

        text = due_raw.strip()

        # ê¸°ë³¸ ì‹œê°„(ë¯¸ì§€ì • ì‹œ 18:00)
        hour = 18
        minute = 0

        # ì˜¤ì „/ì˜¤í›„ ì‹œ:ë¶„
        t = re.search(r"(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ(?:\s*(\d{1,2})ë¶„)?", text)
        if t:
            ampm, hh, mm = t.groups()
            hour = int(hh)
            minute = int(mm) if mm else 0
            if ampm == "ì˜¤í›„" and hour < 12:
                hour += 12
            if ampm == "ì˜¤ì „" and hour == 12:
                hour = 0

        wd_map = {"ì›”": 0, "í™”": 1, "ìˆ˜": 2, "ëª©": 3, "ê¸ˆ": 4, "í† ": 5, "ì¼": 6}
        target_date = None

        # ì˜¤ëŠ˜/ê¸ˆì¼/ëª…ì¼/ë‚´ì¼/ëª¨ë ˆ
        if re.search(r"(ê¸ˆì¼|ì˜¤ëŠ˜)", text):
            target_date = now_kst.date()
        elif re.search(r"(ëª…ì¼|ë‚´ì¼)", text):
            target_date = (now_kst + timedelta(days=1)).date()
        elif "ëª¨ë ˆ" in text:
            target_date = (now_kst + timedelta(days=2)).date()

        # ì´ë²ˆ ì£¼ ìš”ì¼ê¹Œì§€
        if not target_date:
            m = re.search(
                r"(?:ì´ë²ˆ\s*ì£¼|ê¸ˆì£¼)\s*(ì›”|í™”|ìˆ˜|ëª©|ê¸ˆ|í† |ì¼)ìš”ì¼?\s*ê¹Œì§€?", text
            )
            if m:
                wd = m.group(1)
                delta = (wd_map[wd] - now_kst.weekday()) % 7
                target_date = (now_kst + timedelta(days=delta)).date()

        # ë‹¤ìŒ ì£¼/ì°¨ì£¼ ìš”ì¼ê¹Œì§€
        if not target_date:
            m = re.search(
                r"(?:ë‹¤ìŒ\s*ì£¼|ì°¨ì£¼)\s*(ì›”|í™”|ìˆ˜|ëª©|ê¸ˆ|í† |ì¼)ìš”ì¼?\s*ê¹Œì§€?", text
            )
            if m:
                wd = m.group(1)
                delta_to_monday = (0 - now_kst.weekday()) % 7
                next_monday = (
                    now_kst + timedelta(days=delta_to_monday)
                ).date() + timedelta(days=7)
                target_date = next_monday + timedelta(days=wd_map[wd])

        # EOD/EOW
        if not target_date:
            if re.search(r"\bEOD\b", text, re.IGNORECASE):
                target_date = now_kst.date()
                hour, minute = 18, 0
            elif re.search(r"\bEOW\b", text, re.IGNORECASE):
                delta = (4 - now_kst.weekday()) % 7  # ê¸ˆìš”ì¼
                target_date = (now_kst + timedelta(days=delta)).date()
                hour, minute = 18, 0

        # YYYY-MM-DD
        if not target_date:
            m = re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", text)
            if m:
                y, mo, d = map(int, m.groups())
                target_date = datetime(y, mo, d, tzinfo=kst).date()

        # MM/DD
        if not target_date:
            m = re.search(r"\b(\d{1,2})/(\d{1,2})\b", text)
            if m:
                mo, d = map(int, m.groups())
                y = now_kst.year if mo >= now_kst.month else now_kst.year + 1
                target_date = datetime(y, mo, d, tzinfo=kst).date()

        # Nì¼ í›„/ë’¤
        if not target_date:
            m = re.search(r"(\d+)\s*ì¼\s*(?:í›„|ë’¤)", text)
            if m:
                days = int(m.group(1))
                target_date = (now_kst + timedelta(days=days)).date()

        # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: dateutil
        if not target_date:
            try:
                parsed = parser.parse(text, fuzzy=True)
                parsed = (
                    parsed.astimezone(kst)
                    if parsed.tzinfo
                    else parsed.replace(tzinfo=kst)
                )
                target_date = parsed.date()
                hour = parsed.hour or hour
                minute = parsed.minute or minute
            except Exception:
                pass

        # ê·œì¹™ìœ¼ë¡œë„ ëª» êµ¬í•˜ë©´ LLM ë³´ì •
        if not target_date:
            return self._llm_resolve_deadline(
                due_raw=text, received_at_iso=received_at_iso
            )

        due_kst = datetime.combine(target_date, dt_time(hour, minute, tzinfo=kst))
        due_utc_iso = due_kst.astimezone(timezone.utc).isoformat()
        resolved_kst_str = due_kst.strftime("%Y-%m-%d %H:%M KST")
        return resolved_kst_str, due_utc_iso

    # ======================
    # ì•¡ì…˜ ì •ê·œí™”
    # ======================
    def normalize_action(self, raw_action: Dict, email_data: Dict) -> Optional[Dict]:
        """ì•¡ì…˜ ë°ì´í„° ì •ê·œí™” (ê·œì¹™â†’LLM ë³´ì •ìœ¼ë¡œ due í•´ì„, KST/UTC ë™ì‹œ ì œê³µ)"""

        if not raw_action.get("is_action") or not raw_action.get("action"):
            return None

        action = raw_action["action"]
        due_raw = (action.get("due_raw") or "").strip()

        # ----------------------
        # ë‹´ë‹¹ì ê²°ì • (FOLLOW_UP ë³´ê°•)
        # ----------------------
        def _fmt_person(p: Dict[str, str]) -> Optional[str]:
            nm = (p.get("name") or "").strip()
            em = (p.get("email") or "").strip()
            if nm and em:
                return f"{nm} <{em}>"
            return em or (nm if nm else None)

        assignee: Optional[str] = None

        # 1) LLM í›„ë³´ ì¤‘ ì´ë©”ì¼(@)ì´ ìˆëŠ” ê²ƒì„ ìš°ì„  ì„ íƒ
        for cand in action.get("assignee_candidates") or []:
            if cand and "@" in cand:
                assignee = cand.strip()
                break

        # 2) FOLLOW_UPì´ë©´ To/CCì—ì„œ ì²« ëŒ€ìƒ(ë³´ë‚¸ì´/ë¹„ì–´ìˆëŠ” í•­ëª© ì œì™¸)ìœ¼ë¡œ ì§€ì •
        if not assignee and action.get("type") == "FOLLOW_UP":
            sender_email = ((email_data.get("from") or {}).get("email") or "").strip()
            # To ìš°ì„ , ì—†ìœ¼ë©´ CC
            for p in email_data.get("to") or []:
                s = _fmt_person(p)
                if s and (sender_email not in s):
                    assignee = s
                    break
            if not assignee:
                for p in email_data.get("cc") or []:
                    s = _fmt_person(p)
                    if s and (sender_email not in s):
                        assignee = s
                        break

        # 3) í›„ë³´ì— ì´ë©”ì¼ì´ ì—†ì—ˆì§€ë§Œ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
        if not assignee:
            for cand in action.get("assignee_candidates") or []:
                if cand and cand.strip():
                    assignee = cand.strip()
                    break

        if not assignee:
            assignee = "ë¯¸ì§€ì •"

        # ----------------------
        # ê¸°ë³¸ ì‹ ë¢°ë„
        # ----------------------
        confidence = self.default_confidence

        # ----------------------
        # ê¸°í•œ í•´ì„
        # ----------------------
        # 0) LLM ë‹¨ê³„ì—ì„œ ì´ë¯¸ ë„£ì–´ë‘” í•´ì„ê°’ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        due_iso = action.get("due_resolved_iso")
        due_kst_str = action.get("due_resolved_kst")

        # 1) ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜(+LLM ë³´ì • fallback)ìœ¼ë¡œ í•´ì„
        if not due_iso and due_raw:
            rkst, risco = self._resolve_relative_deadline(
                due_raw, email_data.get("receivedAt")
            )
            if risco:
                due_iso = risco
                due_kst_str = rkst
                action["due_resolved_iso"] = risco
                action["due_resolved_kst"] = rkst

        # 2) ì—¬ì „íˆ ì—†ìœ¼ë©´(ì˜ˆì™¸) ë³´ìˆ˜ì  íŒŒì‹± ë°±ì—…
        if not due_iso and due_raw:
            try:
                kst = ZoneInfo("Asia/Seoul")
                now_kst = datetime.now(kst)
                hour = 18
                minute = 0
                t = re.search(r"(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})ì‹œ(?:\s*(\d{1,2})ë¶„)?", due_raw)
                if t:
                    ampm, hh, mm = t.groups()
                    hour = int(hh)
                    minute = int(mm) if mm else 0
                    if ampm == "ì˜¤í›„" and hour < 12:
                        hour += 12
                    if ampm == "ì˜¤ì „" and hour == 12:
                        hour = 0

                target_date = None
                if re.search(r"(ê¸ˆì¼|ì˜¤ëŠ˜)", due_raw):
                    target_date = now_kst.date()
                elif "ë‚´ì¼" in due_raw or "ëª…ì¼" in due_raw:
                    target_date = (now_kst + timedelta(days=1)).date()
                elif re.search(
                    r"(?:ì´ë²ˆ\s*ì£¼|ê¸ˆì£¼)\s*(ì›”|í™”|ìˆ˜|ëª©|ê¸ˆ|í† |ì¼)ìš”ì¼?\s*ê¹Œì§€", due_raw
                ):
                    wd_map = {
                        "ì›”": 0,
                        "í™”": 1,
                        "ìˆ˜": 2,
                        "ëª©": 3,
                        "ê¸ˆ": 4,
                        "í† ": 5,
                        "ì¼": 6,
                    }
                    wd = re.search(
                        r"(?:ì´ë²ˆ\s*ì£¼|ê¸ˆì£¼)\s*(ì›”|í™”|ìˆ˜|ëª©|ê¸ˆ|í† |ì¼)", due_raw
                    ).group(1)
                    delta = (wd_map[wd] - now_kst.weekday()) % 7
                    target_date = (now_kst + timedelta(days=delta)).date()
                elif re.search(r"\d{4}-\d{1,2}-\d{1,2}", due_raw):
                    y, m, d = map(
                        int, re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", due_raw).groups()
                    )
                    target_date = datetime(y, m, d, tzinfo=kst).date()
                elif re.search(r"\b\d{1,2}/\d{1,2}\b", due_raw):
                    m, d = map(
                        int, re.search(r"\b(\d{1,2})/(\d{1,2})\b", due_raw).groups()
                    )
                    y = now_kst.year if m >= now_kst.month else now_kst.year + 1
                    target_date = datetime(y, m, d, tzinfo=kst).date()
                elif re.search(r"\d+\s*ì¼\s*(?:í›„|ë’¤)", due_raw):
                    days = int(re.search(r"(\d+)\s*ì¼\s*(?:í›„|ë’¤)", due_raw).group(1))
                    target_date = (now_kst + timedelta(days=days)).date()

                if not target_date:
                    try:
                        parsed = parser.parse(due_raw, fuzzy=True)
                        parsed = (
                            parsed.astimezone(kst)
                            if parsed.tzinfo
                            else parsed.replace(tzinfo=kst)
                        )
                        target_date = parsed.date()
                        hour = parsed.hour or hour
                        minute = parsed.minute or minute
                    except Exception:
                        pass

                if target_date:
                    due_kst = datetime.combine(
                        target_date, dt_time(hour, minute, tzinfo=kst)
                    )
                    due_iso = due_kst.astimezone(timezone.utc).isoformat()
                    due_kst_str = due_kst.strftime("%Y-%m-%d %H:%M KST")
                    action.setdefault("due_resolved_kst", due_kst_str)
                    action.setdefault("due_resolved_iso", due_iso)
            except Exception as e:
                logging.error(f"ë‚ ì§œ/ì‹œê°„ ì •ê·œí™” ì˜¤ë¥˜: {e}, due_raw: {due_raw}")
                due_iso = None

        # ----------------------
        # ì‹ ë¢°ë„ ë³´ì •
        # ----------------------
        if action.get("type") == "DO" and due_iso and "@" in assignee:
            confidence = min(confidence + 0.2, 1.0)
        elif action.get("type") == "FOLLOW_UP" and due_iso:
            confidence = min(confidence + 0.15, 1.0)

        # ----------------------
        # ë…¸íŠ¸
        # ----------------------
        note_parts = []
        if due_raw:
            note_parts.append(f"ì›ë³¸ ê¸°í•œ: {due_raw}")
        if due_kst_str:
            note_parts.append(f"í•´ì„(KST): {due_kst_str}")

        return {
            "title": action.get("title", ""),
            "assignee": assignee,
            "due": due_iso,  # UTC ISO
            "priority": action.get("priority", "Medium"),
            "tags": action.get("tags", []),
            "type": action.get("type", "DO"),
            "confidence": confidence,
            "notes": " | ".join(note_parts) if note_parts else "",
        }

    # ======================
    # ì²­í‚¹/ì„ë² ë”©/ì—…ë¡œë“œ
    # ======================
    def create_text_chunks(
        self, text: str, chunk_size: int = 900, overlap: int = 150
    ) -> List[str]:
        """í…ìŠ¤íŠ¸ ì²­í‚¹"""

        if len(text) <= chunk_size:
            return [text]

        chunks = []
        start = 0

        while start < len(text):
            end = start + chunk_size

            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸° ì‹œë„
            if end < len(text):
                last_period = text.rfind(".", start, end)
                last_newline = text.rfind("\n", start, end)

                boundary = max(last_period, last_newline)
                if boundary > start + chunk_size // 2:
                    end = boundary + 1

            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)

            start = end - overlap

        return chunks

    def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""

        try:
            response = self.openai_client.embeddings.create(
                model=self.azure_openai_deployment_emb, input=texts
            )

            embeddings = [data.embedding for data in response.data]
            logging.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings)}ê°œ")
            return embeddings

        except Exception as e:
            logging.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # ì„ë² ë”© ì‹¤íŒ¨ì‹œ 0ìœ¼ë¡œ ì±„ìš´ ë”ë¯¸ ë²¡í„° ë°˜í™˜
            return [[0.0] * 1536] * len(texts)

    def upload_to_search(self, email_data: Dict, action_data: Optional[Dict]) -> None:
        """Azure AI Searchì— ë¬¸ì„œ ì—…ë¡œë“œ"""

        # í…ìŠ¤íŠ¸ ì²­í‚¹
        full_text = f"{email_data['subject']}\n\n{email_data['body']}"
        chunks = self.create_text_chunks(full_text)

        # ì„ë² ë”© ìƒì„±
        embeddings = self.get_embeddings(chunks)

        # ê²€ìƒ‰ ë¬¸ì„œ ìƒì„±
        documents = []

        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            # ì›ë³¸ í‚¤ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
            raw_doc_id = f"{email_data['emailId']}::{i}"
            doc_id = self._sanitize_document_key(raw_doc_id)

            logging.info(f"ë¬¸ì„œ í‚¤ ë³€í™˜: '{raw_doc_id}' â†’ '{doc_id}'")

            document = {
                "@search.action": "mergeOrUpload",
                "id": doc_id,
                "emailId": email_data["emailId"],
                "conversationId": email_data["conversationId"],
                "subject": email_data["subject"],
                "from_name": email_data["from"]["name"],
                "from_email": email_data["from"]["email"],
                "to_names": [p["name"] for p in email_data["to"]],
                "cc_names": [p["name"] for p in email_data["cc"]],
                "receivedAt": email_data["receivedAt"],
                "chunk": chunk,
                "bodyPreview": (
                    email_data["body"][:200] + "..."
                    if len(email_data["body"]) > 200
                    else email_data["body"]
                ),
                "chunkEmbedding": embedding,
                "webLink": "",
                "html_body": email_data.get("html_body", ""),
            }

            # ì•¡ì…˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if action_data:
                document.update(
                    {
                        "action": action_data.get("title", ""),
                        "action_type": action_data.get("type", ""),
                        "assignee": action_data.get("assignee", ""),
                        "due": action_data.get("due"),  # UTC ISO or None
                        "priority": action_data.get("priority", ""),
                        "tags": action_data.get("tags", []),
                        "confidence": action_data.get("confidence", 0.0),
                    }
                )

            documents.append(document)

        # ë°°ì¹˜ ì—…ë¡œë“œ
        try:
            result = self.search_client.upload_documents(documents)
            logging.info(f"âœ… Search ì¸ë±ìŠ¤ ì—…ë¡œë“œ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")
            return result

        except Exception as e:
            logging.error(f"âŒ Search ì¸ë±ìŠ¤ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def _sanitize_document_key(self, key: str) -> str:
        """Azure Search ë¬¸ì„œ í‚¤ ì •ì œ"""
        sanitized = re.sub(r"[^a-zA-Z0-9_\-=]", "_", key)
        sanitized = re.sub(r"_+", "_", sanitized)
        sanitized = sanitized.strip("_")
        if len(sanitized) > 1000:
            hash_suffix = hashlib.md5(key.encode()).hexdigest()[:8]
            sanitized = sanitized[:992] + "_" + hash_suffix
        return sanitized

    def save_to_table_storage(self, action_data: Dict, email_data: Dict) -> None:
        """Actions í…Œì´ë¸”ì— ì €ì¥"""

        if not action_data:
            return

        try:
            actions_table = self.table_service.get_table_client("Actions")

            # RowKeyë„ ì •ì œ
            raw_row_key = f"{email_data['emailId']}::0"
            row_key = self._sanitize_document_key(raw_row_key)

            entity = {
                "PartitionKey": "techcorp",
                "RowKey": row_key,
                "subject": email_data["subject"],
                "title": action_data.get("title", ""),
                "assignee": action_data.get("assignee", ""),
                "due": action_data.get("due", ""),  # UTC ISO
                "priority": action_data.get("priority", ""),
                "type": action_data.get("type", ""),
                "tags": ";".join(action_data.get("tags", [])),
                "confidence": action_data.get("confidence", 0.0),
                "receivedAt": email_data["receivedAt"],
                "conversationId": email_data.get("conversationId", ""),
                "webLink": "",
                "done": False,
            }

            actions_table.upsert_entity(entity)
            logging.info(f"âœ… Actions í…Œì´ë¸” ì €ì¥ ì™„ë£Œ: {action_data['title']}")

        except Exception as e:
            logging.error(f"âŒ Actions í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {e}")

    # ======================
    # íŒŒì´í”„ë¼ì¸
    # ======================
    def load_email_data(self, file_path: str) -> List[Dict]:
        """ì´ë©”ì¼ JSON íŒŒì¼ ë¡œë“œ"""

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            emails = data.get("values", [])
            logging.info(f"ğŸ“§ {len(emails)}ê°œ ì´ë©”ì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
            return emails

        except Exception as e:
            logging.error(f"âŒ ì´ë©”ì¼ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def process_emails(self, email_file_path: str) -> Dict:
        """ì´ë©”ì¼ ë°°ì¹˜ ì²˜ë¦¬"""

        logging.info(f"ğŸš€ ì´ë©”ì¼ ì²˜ë¦¬ ì‹œì‘: {email_file_path}")

        # ì´ë©”ì¼ ë°ì´í„° ë¡œë“œ
        emails = self.load_email_data(email_file_path)

        # ì²˜ë¦¬ í†µê³„
        stats = {
            "total_emails": len(emails),
            "processed_emails": 0,
            "actions_extracted": 0,
            "errors": [],
        }

        # ê° ì´ë©”ì¼ ì²˜ë¦¬
        for item in emails:
            try:
                # ì•ˆì „í•œ ë°ì´í„° ì¶”ì¶œ
                if not isinstance(item, dict):
                    logging.warning(f"âš ï¸ ì˜ëª»ëœ ì•„ì´í…œ í˜•ì‹ ê±´ë„ˆëœ€: {type(item)}")
                    continue

                email_data = item.get("data")
                record_id = item.get("recordId", "unknown")

                # data í•„ë“œ ê²€ì¦
                if not email_data:
                    logging.warning(f"âš ï¸ data í•„ë“œê°€ ì—†ëŠ” ë ˆì½”ë“œ ê±´ë„ˆëœ€: {record_id}")
                    continue

                if not isinstance(email_data, dict):
                    logging.warning(
                        f"âš ï¸ data í•„ë“œê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë ˆì½”ë“œ ê±´ë„ˆëœ€: {record_id}"
                    )
                    continue

                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                required_fields = ["subject", "email_body", "from_address"]
                missing_fields = [
                    field for field in required_fields if not email_data.get(field)
                ]

                if missing_fields:
                    logging.warning(
                        f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½ìœ¼ë¡œ ê±´ë„ˆëœ€ {record_id}: {missing_fields}"
                    )
                    continue

                # 1. ì „ì²˜ë¦¬
                standardized_email = self.preprocess_email(email_data)
                logging.info(f"ğŸ“§ ì²˜ë¦¬ ì¤‘: {standardized_email['subject']}")

                # 2. ê° ìˆ˜ì‹ ìë³„ë¡œ ê°œì¸í™”ëœ ë¶„ì„ (ìƒ˜í”Œë¡œ ë°•ì§€í›ˆ ê¸°ì¤€)
                user_context = {
                    "name": "ë°•ì§€í›ˆ",
                    "email": "jihoon.park@techcorp.com",
                    "team": "ë°±ì—”ë“œê°œë°œíŒ€",
                }

                # 3. ì •ì±… ì—”ì§„ ì ìš© (ì›ë³¸ ë°”ë”” ì‚¬ìš©)
                policy_signals = self.analyze_with_policy_engine(
                    email_data, user_context
                )
                logging.info(f"ğŸ“‹ ì •ì±… ë¶„ì„: {policy_signals['policy_decision']}")

                # 4. LLM ì•¡ì…˜ ì¶”ì¶œ(ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜)
                action_result = self.extract_actions_with_llm(
                    standardized_email, policy_signals, user_context
                )

                # 5. ì•¡ì…˜ ì •ê·œí™”(ë§ˆê° í•´ì„ KST/UTC)
                normalized_action = None
                if action_result.get("is_action"):
                    normalized_action = self.normalize_action(
                        action_result, standardized_email
                    )
                    if normalized_action:
                        stats["actions_extracted"] += 1
                        logging.info(f"âš¡ ìµœì¢… ë³´ì • ì™„ë£Œ: {normalized_action}")

                # 6. Azure AI Search ì—…ë¡œë“œ
                self.upload_to_search(standardized_email, normalized_action)

                # 7. Actions í…Œì´ë¸” ì €ì¥
                if normalized_action:
                    self.save_to_table_storage(normalized_action, standardized_email)

                stats["processed_emails"] += 1

            except Exception as e:
                error_msg = f"ì´ë©”ì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {record_id} - {e}"
                logging.error(f"âŒ {error_msg}")
                stats["errors"].append(error_msg)

        # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
        logging.info("ğŸ‰ ì´ë©”ì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        logging.info(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
        logging.info(f"   - ì´ ì´ë©”ì¼: {stats['total_emails']}ê°œ")
        logging.info(f"   - ì²˜ë¦¬ ì„±ê³µ: {stats['processed_emails']}ê°œ")
        logging.info(f"   - ì•¡ì…˜ ì¶”ì¶œ: {stats['actions_extracted']}ê°œ")
        logging.info(f"   - ì˜¤ë¥˜: {len(stats['errors'])}ê°œ")

        return stats


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    try:
        # ì´ë©”ì¼ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        processor = EmailProcessor()

        # ì´ë©”ì¼ íŒŒì¼ ê²½ë¡œ
        email_file = "../data/email_sample.json"

        if not os.path.exists(email_file):
            logging.error(f"âŒ ì´ë©”ì¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {email_file}")
            return

        # ì´ë©”ì¼ ì²˜ë¦¬ ì‹¤í–‰
        results = processor.process_emails(email_file)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print("ğŸ“Š ìµœì¢… ì²˜ë¦¬ ê²°ê³¼")
        print("=" * 50)
        print(f"ì´ ì´ë©”ì¼: {results['total_emails']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {results['processed_emails']}ê°œ")
        print(f"ì•¡ì…˜ ì¶”ì¶œ: {results['actions_extracted']}ê°œ")
        print(f"ì˜¤ë¥˜: {len(results['errors'])}ê°œ")

        if results["errors"]:
            print("\nâŒ ì˜¤ë¥˜ ëª©ë¡:")
            for error in results["errors"]:
                print(f"  - {error}")

        print("\nâœ… ì²˜ë¦¬ ì™„ë£Œ! Azure AI Searchì™€ Table Storageì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    except Exception as e:
        logging.error(f"âŒ ë©”ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    main()
